作业：
    -1. 实现一下Wide&Deep Model的模型/网络结构代码
        假定如下：
            -a. 连续特征： x1, x2, x3
            -b. 离散特征(不同类别)：x4、x5、x6、x7、x8
                NOTE： x4、x5、x6、x8都是单一的id，eg: 13; x7是一个id列表，eg: [2,5,12,3]
                NOTE： x4可取值的数目是2个，x5可取值的数目8个，x6是3个，x7和x8里面的id可取值数目都是20个；
            -c. 先考虑x7列表长度一致的情况(比如长度都为5)，再考虑长度不一致的情况。
            eg:
                数据样例:
                    [0.2, 0.12, 0.45, 0, 6, 1, [1,7,3,5], 14]
                    [0.2, 0.12, 0.45, 0, 6, 1, [1,17,13,5,12], 14]
        模型结构：
            -a. Deep模块输入所有的特征；
            -b. Wide模块仅输入x1、x2、x3、x4、x5
=====================================================================
向量融合方式：
    方式一：所有向量拼接concat；
        缺点：要求向量的数目必须是一样多的；
    方式二：直接将所有向量求均值；
        缺点：合并的时候没有偏向；
    方式三：基于Attention的思路进行向量加权合并；
        缺点：计算量会多一点
    方式四：基于LSTM进行序列特征的提取，作为最终的向量值
    eg:
        样本数据：
            用户点击商品id列表、当前商品id
        样本1
            用户点击商品id列表: [1, 3, 5]
                v11: [....] --> 128维
                v12: [....]
                v13: [....]
            当前商品id: 2
                p11: [....]
        样本2
            用户点击商品id列表: [2, 5, 3, 7]
                v21: [....]
                v22: [....]
                v23: [....]
                v24: [....]
            当前商品id: 9
                p21: [....]
        样本3
            用户点击商品id列表: [1, 3, 5]
                v31: [....]
                v32: [....]
                v33: [....]
            当前商品id: 9
                p31: [....]
            NOTE: 和样本1点击商品id列表这个特征完全一样，只有当前商品id这个特征不一样
        用户点击商品id对应的向量合并:
            方式一：
                样本1: [v11, v12, v13] --> [...., ...., ....] --> 384维向量
                样本2: [v21, v22, v23, v24] --> [...., ...., ...., ....] --> 512维向量
            方式二：
                样本1:
                    v1 = (v11 + v12 + v13) / 3 = [....]  --> 128维向量
                样本2:
                    v2 = (v21 + v22 + v23 + v24) / 4 = [....] --> 128维向量
                样本3：
                    v3 = (v31 + v32 + v33) / 3 = [....] == v1  --> 128维向量
                    NOTE: 此时样本3的点击商品id列表特征对应的向量和样本1的特征向量是同一个
                    NOTE：
                        假设商品的映射关系如下：
                            1 --> 电脑
                            2 --> 鼠标
                            3 --> 外套
                            5 --> 电源线
                            9 --> 裤子
                        样本1:
                            [电脑, 外套, 电源线] 鼠标
                        样本3:
                            [电脑, 外套, 电源线] 裤子
                        从特征融合的希望来讲：
                            样本1融合的特征是不是应该更加偏向 电脑 和 电源线?
                            样本3融合的特征是不是应该更加偏向 外套 ?
                        也就可能由这样一种组合最好了（加权均值的方式）:
                            v1 = 0.5*v11 + 0.1*v12 + 0.4*v13
                            v3 = 0.04*v31 + 0.9*v32 + 0.06*v33
            方式三：
                用当前商品id对应的特征和列表中每个商品id对应的特征计算相似度，然后转换成权重系数，最终加权均值作为最终特征值
                可行的一个步骤：
                    -1. 计算当前样本和列表中所有商品id之间的相关性
                        s1 = F(p11, v11)
                        s2 = F(p11, v12)
                        s3 = F(p11, v13)
                    -2. 将相关性做一个权重转换(softmax)
                        a1, a2, a3 = softmax([s1, s2, s3])
                    -3. 加权均值
                        v1 = a1*v11 + a2*v12 + a3*v13
                attention：
                    注意力机制，也就是将当前关注的特征进行加强、而对不太关注的特征进行减弱；
                    通用的步骤：
                      -1. 计算相关性:
                            计算当前Q和所有的Key之间的相关性
                        -2. 相关性转换为权重系数(softmax)
                        -3. 加权结果：
                            将权重系数和所有对应的Value进行加权求和，结果当作当前输出的V
            方式四：
                以LSTM/RNN/GRU做核心做序列特征提取（LSTM里面针对每条样本而言，输入特征的形状/shape必须是[T,E]的结构，T就表示长度/时刻，E就表示每个时刻的向量大小）
                输入到LSTM的样本转换一下即可:
                    样本1: [p11,v11,v12,v13]
                    样本2: [p21,v21,v22,v23,v24]
                    样本3: [p31,v31,v32,v33] <===> [p31,v11,v12,v13]

===========================================================================
DSSM
    定义两个子模型:
        UserModel：用户侧模型(内部包含特征提取+归一化操作)
        ItemModel：物品测模型(内部包含特征提取+归一化操作)
    训练的伪代码：
        user_x = ... # [N, E1] N表示N个样本，E1表示每个样本/用户用E1维的向量进行展示
        item_x = ... # [N, E2]
        target = [0, 1, ....]  # [N] 0表示用户和物品不相关，1表示相关
        user_feature = UserModel(user_x)  # 提取用户特征，一般情况下:[N,128]
        item_feature = ItemModel(item_x)  # 提取物体特征，一般情况下:[N,128]
        sim = torch.sum(user_feature * item_feature, dim=1)  # [N]
        loss = .... # 使用sigmoid的损失就可以了
    NOTE：
        用户、物品这个名称只是为了区分好理解，所以叫的。
        有的时候，用户侧和商品侧是同一个模型&参数是共享的。